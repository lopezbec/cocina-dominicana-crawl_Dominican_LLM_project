# Multi-Site Web Scraper Environment Configuration
# Copy this file to .env and fill in your actual values

# =============================================================================
# REQUIRED CONFIGURATION
# =============================================================================

# Domain to crawl (REQUIRED)
# Example: example.com
# This must match a directory name in sites/ (with dots replaced by underscores)
CRAWL_DOMAIN=<domain>

# =============================================================================
# LOCAL FIRECRAWL CONFIGURATION
# =============================================================================

# Firecrawl API URL (Local Docker setup)
# Default: http://localhost:3002
# Do not change unless you modified docker-compose.yml ports
FIRECRAWL_API_URL=http://localhost:3002

# =============================================================================
# OPTIONAL CONFIGURATION
# =============================================================================

# Logging Level
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
# Default: INFO
# LOG_LEVEL=INFO

# Output Directory
# Directory where scraped content will be saved
# Default: scraped_content
# OUTPUT_DIR=scraped_content

# Scraping Configuration
# These settings can be overridden in config.yaml
# Base delay between requests in seconds (local has no rate limits)
# Default: 0.5 seconds
# SCRAPE_DELAY=0.5

# Maximum retry attempts for failed requests
# Default: 3 attempts
# MAX_RETRIES=3

# Maximum crawl depth for category crawling
# Default: 2 levels
# MAX_CRAWL_DEPTH=2

# =============================================================================
# PERFORMANCE TUNING
# =============================================================================
#
# To adjust scraping speed, edit firecrawl.env:
#
# NUM_WORKERS_PER_QUEUE=8   (default, balanced)
# NUM_WORKERS_PER_QUEUE=16  (faster, more resources)
# NUM_WORKERS_PER_QUEUE=32  (very fast, high resources)
#
# After changes: docker-compose restart firecrawl-api